{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOC1Bce3Sz2+LVH1Ktxyx+6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Transformer para series de tiempo"],"metadata":{"id":"QBQAsxOyppU3"}},{"cell_type":"markdown","source":["## Importación de librerias a utilizar"],"metadata":{"id":"fyNcYz7Qphso"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"51iBKtwgpdOT","executionInfo":{"status":"ok","timestamp":1670629714156,"user_tz":360,"elapsed":849,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","from pathlib import Path\n","import os\n","from typing import Optional, Any, Union, Callable, Tuple"]},{"cell_type":"code","source":["from torch import nn, Tensor\n","from torch.optim import Adam\n","from torch.nn import MSELoss\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","import math"],"metadata":{"id":"0_5bsgTHmZEc","executionInfo":{"status":"ok","timestamp":1670629717373,"user_tz":360,"elapsed":3220,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Lectura de datos"],"metadata":{"id":"Y8JB_Idkp9iO"}},{"cell_type":"markdown","source":["Se importan los datos con los delitos homogenizados construidos anteriormente."],"metadata":{"id":"5Z4f_J2CqARq"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","path=\"/content/drive/My Drive/Proyecto_CD/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mWP1g4yFpzcB","executionInfo":{"status":"ok","timestamp":1670629718223,"user_tz":360,"elapsed":855,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}},"outputId":"fd73d7bd-be6a-4426-e05e-f75c477ef742"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["FGJ_carpetas = pd.read_csv(path+'FGJ_carpetas_homo.csv', parse_dates=[\"fecha_hechos\"]) \n","FGJ_carpetas.index = pd.DatetimeIndex(FGJ_carpetas.fecha_hechos)"],"metadata":{"id":"X4LmlNifp8bQ","executionInfo":{"status":"ok","timestamp":1670629726645,"user_tz":360,"elapsed":8425,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["top_cat=FGJ_carpetas['categoria_delito_homo'].value_counts().index[1:11]\n","cat = top_cat[top_cat!=\"HECHO NO DELICTIVO\"]"],"metadata":{"id":"JflGYk5NqrKp","executionInfo":{"status":"ok","timestamp":1670629726897,"user_tz":360,"elapsed":11,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["FGJ_carpetas[FGJ_carpetas[\"categoria_delito_homo\"] == cat[0]]"],"metadata":{"id":"PvwWecIsr1yt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ts_hour = FGJ_carpetas.pivot_table(\"delito\",columns=\"categoria_delito_homo\", index = FGJ_carpetas['fecha_hechos'].dt.to_period('H'), \n","                        aggfunc=np.size, fill_value=0)"],"metadata":{"id":"D-3rBgaaNfTs","executionInfo":{"status":"ok","timestamp":1670629740352,"user_tz":360,"elapsed":13219,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Arquitectura"],"metadata":{"id":"HzsSrec3k90z"}},{"cell_type":"code","source":["class PositionalEncoder(nn.Module):\n","    \"\"\"Adapted from:  https://pytorch.org/tutorials/beginner/transformer_tutorial.html\"\"\"\n","\n","    def __init__(self, dropout: float=0.1, \n","        max_seq_len: int=5000, d_model: int=512,batch_first: bool=False):\n","        \"\"\"\n","        Parameters:\n","            dropout: the dropout rate\n","            max_seq_len: the maximum length of the input sequences\n","            d_model: The dimension of the output of sub-layers in the model \n","                     (Vaswani et al, 2017)\n","        \"\"\"\n","        super().__init__()\n","        self.d_model = d_model\n","        self.dropout = nn.Dropout(p=dropout)\n","        self.batch_first = batch_first\n","\n","        # adapted from PyTorch tutorial\n","        position = torch.arange(max_seq_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n","        \n","        if self.batch_first:\n","            pe = torch.zeros(1, max_seq_len, d_model)\n","            pe[0, :, 0::2] = torch.sin(position * div_term)\n","            pe[0, :, 1::2] = torch.cos(position * div_term)\n","        else:\n","            pe = torch.zeros(max_seq_len, 1, d_model)\n","            pe[:, 0, 0::2] = torch.sin(position * div_term)\n","            pe[:, 0, 1::2] = torch.cos(position * div_term)\n","        self.register_buffer('pe', pe)\n","        \n","    def forward(self, x: Tensor) -> Tensor:\n","        \"\"\"Args:\n","            x: Tensor, shape [batch_size, enc_seq_len, dim_val] or \n","               [enc_seq_len, batch_size, dim_val]\n","        \"\"\"\n","        if self.batch_first:\n","            x = x + self.pe[:,:x.size(1)]\n","        else:\n","            x = x + self.pe[:x.size(0)]\n","\n","        return self.dropout(x)"],"metadata":{"id":"Jtcd_6BnFoxg","executionInfo":{"status":"ok","timestamp":1670629740352,"user_tz":360,"elapsed":17,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class TimeSeriesTransformer(nn.Module):\n","    \"\"\"\n","    This class implements a transformer model that can be used for times series\n","    forecasting. This time series transformer model is based on the paper by\n","    Wu et al (2020) [1]. \n","    https://towardsdatascience.com/how-to-make-a-pytorch-transformer-for-time-series-forecasting-69e073d4061e\n","    [1] Wu, N., Green, B., Ben, X., O'banion, S. (2020). \n","    'Deep Transformer Models for Time Series Forecasting: \n","    The Influenza Prevalence Case'. \n","    arXiv:2001.08317 [cs, stat] [Preprint]. \n","    Available at: http://arxiv.org/abs/2001.08317 (Accessed: 9 March 2022).\n","    \"\"\"\n","    def __init__(self, input_size: int, dec_seq_len: int, batch_first: bool, out_seq_len: int=58, dim_val: int=512, \n","                 n_encoder_layers: int=4, n_decoder_layers: int=4, n_heads: int=8,dropout_encoder: float=0.2, dropout_decoder: float=0.2,\n","                 dropout_pos_enc: float=0.1, dim_feedforward_encoder: int=2048,dim_feedforward_decoder: int=2048,\n","                 num_predicted_features: int=1): \n","\n","        \"\"\"\n","        Args:\n","            input_size: int, number of input variables. 1 if univariate.\n","            dec_seq_len: int, the length of the input sequence fed to the decoder\n","            dim_val: int, aka d_model. All sub-layers in the model produce \n","                     outputs of dimension dim_val\n","            n_encoder_layers: int, number of stacked encoder layers in the encoder\n","            n_decoder_layers: int, number of stacked encoder layers in the decoder\n","            n_heads: int, the number of attention heads (aka parallel attention layers)\n","            dropout_encoder: float, the dropout rate of the encoder\n","            dropout_decoder: float, the dropout rate of the decoder\n","            dropout_pos_enc: float, the dropout rate of the positional encoder\n","            dim_feedforward_encoder: int, number of neurons in the linear layer \n","                                     of the encoder\n","            dim_feedforward_decoder: int, number of neurons in the linear layer \n","                                     of the decoder\n","            num_predicted_features: int, the number of features you want to predict.\n","                                    Most of the time, this will be 1 because we're\n","                                    only forecasting FCR-N prices in DK2, but in\n","                                    we wanted to also predict FCR-D with the same\n","                                    model, num_predicted_features should be 2.\n","        \"\"\"\n","        super().__init__() \n","        self.dec_seq_len = dec_seq_len\n","\n","        # Creating the three linear layers needed for the model\n","        self.encoder_input_layer = nn.Linear(in_features=input_size, out_features=dim_val)\n","        self.decoder_input_layer = nn.Linear(in_features=num_predicted_features,out_features=dim_val)  \n","        self.linear_mapping = nn.Linear(in_features=dim_val,out_features=num_predicted_features)\n","\n","        # Create positional encoder\n","        self.positional_encoding_layer = PositionalEncoder( d_model=dim_val,dropout=dropout_pos_enc)\n","\n","        # The encoder layer used in the paper is identical to the one used by\n","        # Vaswani et al (2017) on which the PyTorch module is based.\n","        encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=dim_val, \n","            nhead=n_heads,\n","            dim_feedforward=dim_feedforward_encoder,\n","            dropout=dropout_encoder,\n","            batch_first=batch_first\n","            )\n","\n","        # Stack the encoder layers in nn.TransformerDecode\n","        self.encoder = nn.TransformerEncoder(encoder_layer=encoder_layer,num_layers=n_encoder_layers,norm=None)\n","\n","        decoder_layer = nn.TransformerDecoderLayer(\n","            d_model=dim_val,\n","            nhead=n_heads,\n","            dim_feedforward=dim_feedforward_decoder,\n","            dropout=dropout_decoder,\n","            batch_first=batch_first\n","            )\n","\n","        self.decoder = nn.TransformerDecoder(decoder_layer=decoder_layer,num_layers=n_decoder_layers, norm=None)\n","\n","    def forward(self, src: Tensor, tgt: Tensor, src_mask: Tensor=None, \n","                tgt_mask: Tensor=None) -> Tensor:\n","        \"\"\"\n","        Returns a tensor of shape:\n","        [target_sequence_length, batch_size, num_predicted_features]\n","        \n","        Args:\n","            src: the encoder's output sequence. Shape: (S,E) for unbatched input, \n","                 (S, N, E) if batch_first=False or (N, S, E) if \n","                 batch_first=True, where S is the source sequence length, \n","                 N is the batch size, and E is the number of features (1 if univariate)\n","            tgt: the sequence to the decoder. Shape: (T,E) for unbatched input, \n","                 (T, N, E)(T,N,E) if batch_first=False or (N, T, E) if \n","                 batch_first=True, where T is the target sequence length, \n","                 N is the batch size, and E is the number of features (1 if univariate)\n","            src_mask: the mask for the src sequence to prevent the model from \n","                      using data points from the target sequence\n","            tgt_mask: the mask for the tgt sequence to prevent the model from\n","                      using data points from the target sequence\n","        \"\"\"\n","        # Pass throguh the input layer right before the encoder\n","        src = self.encoder_input_layer(src) # src shape: [batch_size, src length, dim_val] regardless of number of input features\n","        # Pass through the positional encoding layer\n","        src = self.positional_encoding_layer(src) # src shape: [batch_size, src length, dim_val] regardless of number of input features\n","        src = self.encoder(src=src) # src shape: [batch_size, enc_seq_len, dim_val]\n","        # Pass decoder input through decoder input layer\n","        decoder_output = self.decoder_input_layer(tgt) # src shape: [target sequence length, batch_size, dim_val] regardless of number of input features\n","        # Pass throguh decoder - output shape: [batch_size, target seq len, dim_val]\n","        decoder_output = self.decoder(tgt=decoder_output,memory=src, tgt_mask=tgt_mask, memory_mask=src_mask)\n","        # Pass through linear mapping\n","        decoder_output = self.linear_mapping(decoder_output) # shape [batch_size, target seq len]\n","        return decoder_output"],"metadata":{"id":"FQy1icoRDseu","executionInfo":{"status":"ok","timestamp":1670629740353,"user_tz":360,"elapsed":16,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class TransformerDataset(Dataset):\n","    \"\"\"Dataset class used for transformer models.\"\"\"\n","    def __init__(self, data: torch.tensor,indices: list, enc_seq_len: int, dec_seq_len: int, target_seq_len: int) -> None:\n","\n","        \"\"\"\n","        Args:\n","            data: tensor, the entire train, validation or test data sequence \n","                        before any slicing. If univariate, data.size() will be \n","                        [number of samples, number of variables]\n","                        where the number of variables will be equal to 1 + the number of\n","                        exogenous variables. Number of exogenous variables would be 0 if univariate.\n","            indices: a list of tuples. Each tuple has two elements:\n","                     1) the start index of a sub-sequence\n","                     2) the end index of a sub-sequence. \n","                     The sub-sequence is split into src, trg and trg_y later.  \n","            enc_seq_len: int, the desired length of the input sequence given to the\n","                     the first layer of the transformer model.\n","            target_seq_len: int, the desired length of the target sequence (the output of the model)\n","            target_idx: The index position of the target variable in data. Data is a 2D tensor\n","        \"\"\"      \n","        super().__init__()\n","        self.indices = indices\n","        self.data = data\n","\n","        print(\"From get_src_trg: data size = {}\".format(data.size()))\n","\n","        self.enc_seq_len = enc_seq_len\n","        self.dec_seq_len = dec_seq_len\n","        self.target_seq_len = target_seq_len\n","\n","    def __len__(self):        \n","        return len(self.indices)\n","\n","    def __getitem__(self, index):\n","        \"\"\"Returns a tuple with 3 elements:\n","        1) src (the encoder input)\n","        2) trg (the decoder input)\n","        3) trg_y (the target)\n","        \"\"\"\n","        # Get the first element of the i'th tuple in the list self.indicesasdfas\n","        start_idx = self.indices[index][0]\n","\n","        # Get the second (and last) element of the i'th tuple in the list self.indices\n","        end_idx = self.indices[index][1]\n","        sequence = self.data[start_idx:end_idx]\n","\n","        #print(\"From __getitem__: sequence length = {}\".format(len(sequence)))\n","        src, trg, trg_y = self.get_src_trg(\n","            sequence=sequence,\n","            enc_seq_len=self.enc_seq_len,\n","            dec_seq_len=self.dec_seq_len,\n","            target_seq_len=self.target_seq_len\n","            )\n","        return src, trg, trg_y\n","    \n","    def get_src_trg(self,sequence: torch.Tensor, enc_seq_len: int, dec_seq_len: int, target_seq_len: int) -> Tuple[torch.tensor, torch.tensor, torch.tensor]:\n","        \"\"\"\n","        Generate the src (encoder input), trg (decoder input) and trg_y (the target)\n","        sequences from a sequence. \n","        Args:\n","            sequence: tensor, a 1D tensor of length n where \n","                    n = encoder input length + target sequence length  \n","            enc_seq_len: int, the desired length of the input to the transformer encoder\n","            target_seq_len: int, the desired length of the target sequence (the \n","                            one against which the model output is compared)\n","        Return: \n","            src: tensor, 1D, used as input to the transformer model\n","            trg: tensor, 1D, used as input to the transformer model\n","            trg_y: tensor, 1D, the target sequence against which the model output\n","                is compared when computing loss. \n","        \"\"\"\n","        assert len(sequence) == enc_seq_len + target_seq_len, \"Sequence length does not equal (input length + target length)\"\n","        # encoder input\n","        src = sequence[:enc_seq_len] \n","        # decoder input.\n","        trg = sequence[enc_seq_len-1:len(sequence)-1]\n","        assert len(trg) == target_seq_len, \"Length of trg does not match target sequence length\"\n","        # The target sequence against which the model output will be compared to compute loss\n","        trg_y = sequence[-target_seq_len:]\n","        assert len(trg_y) == target_seq_len, \"Length of trg_y does not match target sequence length\"\n","        return src, trg, trg_y.squeeze(-1) # change size from [batch_size, target_seq_len, num_features] to [batch_size, target_seq_len] "],"metadata":{"id":"kJt46QJ371JC","executionInfo":{"status":"ok","timestamp":1670629740353,"user_tz":360,"elapsed":16,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def generate_square_subsequent_mask(dim1: int, dim2: int) -> Tensor:\n","    \"\"\"\n","    Generates an upper-triangular matrix of -inf, with zeros on diag.\n","    Modified from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n","    Args:\n","        dim1: int, for both src and tgt masking, this must be target sequence\n","              length\n","        dim2: int, for src masking this must be encoder sequence length (i.e. \n","              the length of the input sequence to the model), \n","              and for tgt masking, this must be target sequence length \n","    Return:\n","        A Tensor of shape [dim1, dim2]\n","    \"\"\"\n","    return torch.triu(torch.ones(dim1, dim2) * float('-inf'), diagonal=1)\n","\n","\n","def get_indices_input_target(num_obs, input_len, step_size, forecast_horizon, target_len):\n","        \"\"\"\n","        Produce all the start and end index positions of all sub-sequences.\n","        The indices will be used to split the data into sub-sequences on which \n","        the models will be trained. \n","        Returns a tuple with four elements:\n","        1) The index position of the first element to be included in the input sequence\n","        2) The index position of the last element to be included in the input sequence\n","        3) The index position of the first element to be included in the target sequence\n","        4) The index position of the last element to be included in the target sequence\n","        \n","        Args:\n","            num_obs (int): Number of observations in the entire dataset for which\n","                            indices must be generated.\n","            input_len (int): Length of the input sequence (a sub-sequence of \n","                             of the entire data sequence)\n","            step_size (int): Size of each step as the data sequence is traversed.\n","                             If 1, the first sub-sequence will be indices 0-input_len, \n","                             and the next will be 1-input_len.\n","            forecast_horizon (int): How many index positions is the target away from\n","                                    the last index position of the input sequence?\n","                                    If forecast_horizon=1, and the input sequence\n","                                    is data[0:10], the target will be data[11:taget_len].\n","            target_len (int): Length of the target / output sequence.\n","        \"\"\"\n","\n","        input_len = round(input_len) # just a precaution\n","        start_position = 0\n","        stop_position = num_obs-1 # because of 0 indexing\n","        \n","        subseq_first_idx = start_position\n","        subseq_last_idx = start_position + input_len\n","        target_first_idx = subseq_last_idx + forecast_horizon\n","        target_last_idx = target_first_idx + target_len \n","        print(\"target_last_idx is {}\".format(target_last_idx))\n","        print(\"stop_position is {}\".format(stop_position))\n","        indices = []\n","        while target_last_idx <= stop_position:\n","            indices.append((subseq_first_idx, subseq_last_idx, target_first_idx, target_last_idx))\n","            subseq_first_idx += step_size\n","            subseq_last_idx += step_size\n","            target_first_idx = subseq_last_idx + forecast_horizon\n","            target_last_idx = target_first_idx + target_len\n","\n","        return indices\n","\n","def get_indices_entire_sequence(data: pd.DataFrame, window_size: int, step_size: int) -> list:\n","        \"\"\"\n","        Produce all the start and end index positions that is needed to produce\n","        the sub-sequences. \n","        Returns a list of tuples. Each tuple is (start_idx, end_idx) of a sub-\n","        sequence. These tuples should be used to slice the dataset into sub-\n","        sequences. These sub-sequences should then be passed into a function\n","        that slices them into input and target sequences. \n","        \n","        Args:\n","            num_obs (int): Number of observations (time steps) in the entire \n","                           dataset for which indices must be generated, e.g. \n","                           len(data)\n","            window_size (int): The desired length of each sub-sequence. Should be\n","                               (input_sequence_length + target_sequence_length)\n","                               E.g. if you want the model to consider the past 100\n","                               time steps in order to predict the future 50 \n","                               time steps, window_size = 100+50 = 150\n","            step_size (int): Size of each step as the data sequence is traversed \n","                             by the moving window.\n","                             If 1, the first sub-sequence will be [0:window_size], \n","                             and the next will be [1:window_size].\n","        Return:\n","            indices: a list of tuples\n","        \"\"\"\n","\n","        stop_position = len(data)-1 # 1- because of 0 indexing\n","        \n","        # Start the first sub-sequence at index position 0\n","        subseq_first_idx = 0\n","        \n","        subseq_last_idx = window_size\n","        \n","        indices = []\n","        \n","        while subseq_last_idx <= stop_position:\n","\n","            indices.append((subseq_first_idx, subseq_last_idx))\n","            \n","            subseq_first_idx += step_size\n","            \n","            subseq_last_idx += step_size\n","\n","        return indices"],"metadata":{"id":"NDpWIFrHB6Yv","executionInfo":{"status":"ok","timestamp":1670629740354,"user_tz":360,"elapsed":16,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def read_data(data_dir: Union[str, Path] = \"data\",  \n","    timestamp_col_name: str=\"timestamp\") -> pd.DataFrame:\n","    \"\"\"\n","    Read data from csv file and return pd.Dataframe object\n","    Args:\n","        data_dir: str or Path object specifying the path to the directory \n","                  containing the data\n","        target_col_name: str, the name of the column containing the target variable\n","        timestamp_col_name: str, the name of the column or named index \n","                            containing the timestamps\n","    \"\"\"\n","\n","    # Ensure that `data_dir` is a Path object\n","    data_dir = Path(data_dir)\n","\n","    # Read csv file\n","    csv_files = list(data_dir.glob(\"*.csv\"))\n","    \n","    if len(csv_files) > 1:\n","        raise ValueError(\"data_dir contains more than 1 csv file. Must only contain 1\")\n","    elif len(csv_files) == 0:\n","        raise ValueError(\"data_dir must contain at least 1 csv file.\")\n","\n","    data_path = csv_files[0]\n","    print(\"Reading file in {}\".format(data_path))\n","\n","    data = pd.read_csv(\n","        data_path, \n","        parse_dates=[timestamp_col_name], \n","        index_col=[timestamp_col_name], \n","        infer_datetime_format=True,\n","        low_memory=False\n","    )\n","\n","    # Make sure all \"n/e\" values have been removed from df. \n","    if is_ne_in_df(data):\n","        raise ValueError(\"data frame contains 'n/e' values. These must be handled\")\n","\n","    data = to_numeric_and_downcast_data(data)\n","    # Make sure data is in ascending order by timestamp\n","    data.sort_values(by=[timestamp_col_name], inplace=True)\n","\n","    return data\n","\n","def is_ne_in_df(df:pd.DataFrame):\n","    \"\"\"\n","    Some raw data files contain cells with \"n/e\". This function checks whether\n","    any column in a df contains a cell with \"n/e\". Returns False if no columns\n","    contain \"n/e\", True otherwise\n","    \"\"\"\n","    for col in df.columns:\n","        true_bool = (df[col] == \"n/e\")\n","        if any(true_bool):\n","            return True\n","\n","    return False\n","\n","\n","def to_numeric_and_downcast_data(df: pd.DataFrame):\n","    \"\"\"Downcast columns in df to smallest possible version of it's existing data type\"\"\"\n","    fcols = df.select_dtypes('float').columns\n","    icols = df.select_dtypes('integer').columns\n","    df[fcols] = df[fcols].apply(pd.to_numeric, downcast='float')\n","    df[icols] = df[icols].apply(pd.to_numeric, downcast='integer')\n","\n","    return df"],"metadata":{"id":"ci9ZOCa2EbZc","executionInfo":{"status":"ok","timestamp":1670629785795,"user_tz":360,"elapsed":182,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def run_encoder_decoder_inference(model: nn.Module, src: torch.Tensor, forecast_window: int,batch_size: int,device, batch_first: bool=False) -> torch.Tensor:\n","    \"\"\"\n","    NB! This function is currently only tested on models that work with batch_first = False\n","    This function is for encoder-decoder type models in which the decoder requires\n","    an input, tgt, which - during training - is the target sequence. During inference,\n","    the values of tgt are unknown, and the values therefore have to be generated iteratively.  \n","    This function returns a prediction of length forecast_window for each batch in src\n","    \n","    Args:\n","        model: An encoder-decoder type model where the decoder requires\n","               target values as input. Should be set to evaluation mode before \n","               passed to this function.\n","        src: The input to the model\n","        forecast_horizon: The desired length of the model's output, e.g. 58 if you\n","                         want to predict the next 58 hours of FCR prices.\n","        batch_size: batch size\n","        batch_first: If true, the shape of the model input should be \n","                     [batch size, input sequence length, number of features].\n","                     If false, [input sequence length, batch size, number of features]\n","    \"\"\"\n","\n","    # Dimension of a batched model input that contains the target sequence values\n","    target_seq_dim = 0 if batch_first == False else 1\n","    # Take the last value of thetarget variable in all batches in src and make it tgt as per the Influenza paper\n","    tgt = src[-1, :, 0] if batch_first == False else src[:, -1, 0] # shape [1, batch_size, 1]\n","    # Change shape from [batch_size] to [1, batch_size, 1]\n","    if batch_size == 1 and batch_first == False:\n","        tgt = tgt.unsqueeze(0).unsqueeze(0) # change from [1] to [1, 1, 1]\n","    # Change shape from [batch_size] to [1, batch_size, 1]\n","    if batch_first == False and batch_size > 1:\n","        tgt = tgt.unsqueeze(0).unsqueeze(-1)\n","\n","    # Iteratively concatenate tgt with the first element in the prediction\n","    for _ in range(forecast_window-1):\n","        # Create masks\n","        dim_a = tgt.shape[1] if batch_first == True else tgt.shape[0]\n","        dim_b = src.shape[1] if batch_first == True else src.shape[0]\n","        tgt_mask = generate_square_subsequent_mask(dim1=dim_a,dim2=dim_a,device=device)\n","        src_mask = generate_square_subsequent_mask(dim1=dim_a,dim2=dim_b,device=device)\n","\n","        # Make prediction\n","        prediction = model(src, tgt, src_mask, tgt_mask) \n","\n","        # If statement simply makes sure that the predicted value is \n","        # extracted and reshaped correctly\n","        if batch_first == False:\n","            # Obtain the predicted value at t+1 where t is the last time step represented in tgt\n","            last_predicted_value = prediction[-1, :, :] \n","            # Reshape from [batch_size, 1] --> [1, batch_size, 1]\n","            last_predicted_value = last_predicted_value.unsqueeze(0)\n","\n","        else:\n","            # Obtain predicted value\n","            last_predicted_value = prediction[:, -1, :]\n","            # Reshape from [batch_size, 1] --> [batch_size, 1, 1]\n","            last_predicted_value = last_predicted_value.unsqueeze(-1)\n","\n","        # Detach the predicted element from the graph and concatenate with tgt in dimension 1 or 0\n","        tgt = torch.cat((tgt, last_predicted_value.detach()), target_seq_dim)\n","    \n","    # Create masks\n","    dim_a = tgt.shape[1] if batch_first == True else tgt.shape[0]\n","    dim_b = src.shape[1] if batch_first == True else src.shape[0]\n","    tgt_mask = generate_square_subsequent_mask(dim1=dim_a,dim2=dim_a,device=device)\n","    src_mask = generate_square_subsequent_mask(dim1=dim_a,dim2=dim_b,device=device)\n","\n","    # Make final prediction\n","    final_prediction = model(src, tgt, src_mask, tgt_mask)\n","\n","    return final_prediction"],"metadata":{"id":"FC2e3C_M-2x0","executionInfo":{"status":"ok","timestamp":1670629790337,"user_tz":360,"elapsed":177,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# Datos y entrenamiento"],"metadata":{"id":"qzEViJqCOEfn"}},{"cell_type":"code","source":["# Hyperparams\n","test_size = 0.2\n","batch_size = 128\n","\n","## Params\n","dim_val = 216 #512\n","n_heads = 8\n","n_decoder_layers = 4\n","n_encoder_layers = 4\n","dec_seq_len = 46 # 92 # length of input given to decoder\n","enc_seq_len = 168 #153 # length of input given to encoder\n","output_sequence_length = 48 # target sequence length. If hourly data and length = 48, you predict 2 days ahead\n","window_size = enc_seq_len + output_sequence_length # used to slice data into sub-sequences\n","step_size = 168 # Step size, i.e. how many time steps does the moving window move at each step\n","in_features_encoder_linear_layer = 1024\n","in_features_decoder_linear_layer = 1024\n","max_seq_len = enc_seq_len\n","batch_first = True\n","learning_rate = 1e-3"],"metadata":{"id":"ASh6rjG0NHk_","executionInfo":{"status":"ok","timestamp":1670634329468,"user_tz":360,"elapsed":178,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["data = pd.DataFrame({'FCR_N_PriceEUR':ts_hour['AMENAZAS'].values,'timestamp':ts_hour.index})\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"zW5RjkMSNl_x","executionInfo":{"status":"ok","timestamp":1670634332833,"user_tz":360,"elapsed":605,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}},"outputId":"aa42dd3c-4df6-4a03-e1ea-d1a708e38084"},"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   FCR_N_PriceEUR         timestamp\n","0               3  2016-01-01 00:00\n","1               3  2016-01-01 01:00\n","2               0  2016-01-01 02:00\n","3               0  2016-01-01 03:00\n","4               0  2016-01-01 04:00"],"text/html":["\n","  <div id=\"df-1899857c-663f-405d-915b-56b74245f4b9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>FCR_N_PriceEUR</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>2016-01-01 00:00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>2016-01-01 01:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>2016-01-01 02:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>2016-01-01 03:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>2016-01-01 04:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1899857c-663f-405d-915b-56b74245f4b9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1899857c-663f-405d-915b-56b74245f4b9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1899857c-663f-405d-915b-56b74245f4b9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["target_col_name = \"FCR_N_PriceEUR\"\n","timestamp_col = \"timestamp\"\n","# Only use data from this date and onwards\n","cutoff_date = datetime(2018, 1, 1) "],"metadata":{"id":"DyKXilL0NQCM","executionInfo":{"status":"ok","timestamp":1670634334078,"user_tz":360,"elapsed":187,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["# Define input variables \n","exogenous_vars = [] # should contain strings. Each string must correspond to a column name\n","input_variables = [target_col_name] + exogenous_vars\n","target_idx = 0 # index position of target in batched trg_y\n","input_size = len(input_variables)"],"metadata":{"id":"128sdnXzNU6E","executionInfo":{"status":"ok","timestamp":1670634335391,"user_tz":360,"elapsed":170,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["# Read data\n","#data = read_data(timestamp_col_name=timestamp_col)"],"metadata":{"id":"sAeTQv6eNW_j","executionInfo":{"status":"ok","timestamp":1670631258400,"user_tz":360,"elapsed":193,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["# Remove test data from dataset\n","training_data = data[:-(round(len(data)*test_size))]\n","# Make list of (start_idx, end_idx) pairs that are used to slice the time series sequence into chunkc. \n","# Should be training data indices only\n","training_indices = get_indices_entire_sequence(data=training_data, window_size=window_size, step_size=step_size)\n","# Making instance of custom dataset class\n","training_data = TransformerDataset(data=torch.tensor(training_data[input_variables].values).float(),indices=training_indices,enc_seq_len=enc_seq_len,dec_seq_len=dec_seq_len,target_seq_len=output_sequence_length)\n","# Making dataloader\n","training_data = DataLoader(training_data, batch_size)\n","\n","i, batch = next(enumerate(training_data))\n","src, trg, trg_y = batch\n","print(\"src shape {}\".format(src.shape))\n","print(\"src shape {}\".format(src.shape))\n","# Permute from shape [batch size, seq len, num features] to [seq len, batch size, num features]\n","#if batch_first == False:\n","#    shape_before = src.shape\n","#    src = src.permute(1, 0, 2)\n","#    shape_before = trg.shape\n","#    trg = trg.permute(1, 0, 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OOXRsrvpLqiM","executionInfo":{"status":"ok","timestamp":1670634337971,"user_tz":360,"elapsed":267,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}},"outputId":"6dff20d3-29f2-49a3-a5c0-3c17f9658bff"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["From get_src_trg: data size = torch.Size([45552, 1])\n","src shape torch.Size([128, 168, 1])\n","src shape torch.Size([128, 168, 1])\n"]}]},{"cell_type":"code","source":["model = TimeSeriesTransformer(input_size=len(input_variables),dec_seq_len=enc_seq_len,batch_first=batch_first,\n","                              num_predicted_features=1)"],"metadata":{"id":"_xVaLxAPOrmm","executionInfo":{"status":"ok","timestamp":1670634342307,"user_tz":360,"elapsed":163,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["epochs = 1\n","\n","optimizer = Adam(model.parameters(), lr=learning_rate)\n","criterion = MSELoss()\n","\n","# Iterate over all epochs\n","for epoch in range(epochs):\n","    # Iterate over all (x,y) pairs in training dataloader\n","    for i, (src, trg, tgt_y) in enumerate(training_data):\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","        \n","        # Make src mask for decoder with size:  [batch_size*n_heads, output_sequence_length, enc_seq_len]\n","        src_mask = generate_square_subsequent_mask(dim1=output_sequence_length,dim2=enc_seq_len)\n","        # Make tgt mask for decoder with size:[batch_size*n_heads, output_sequence_length, output_sequence_length]\n","        tgt_mask = generate_square_subsequent_mask(dim1=output_sequence_length,dim2=output_sequence_length)\n","\n","        if batch_first == False:\n","          src = src.permute(1, 0, 2)\n","          trg = trg.permute(1, 0, 2)\n","\n","        # Make forecasts\n","        prediction = model(src=src,tgt=trg,src_mask=src_mask,tgt_mask=tgt_mask)\n","  \n","        if input_size==1:\n","          tgt_y = tgt_y.unsqueeze(2)\n","        # Compute and backprop loss\n","        loss = criterion(tgt_y, prediction)\n","        loss.backward()\n","        # Take optimizer step\n","        optimizer.step()\n","\n","    # Iterate over all (x,y) pairs in validation dataloader\n","    #model.eval()\n","    #with torch.no_grad():\n","    #    for i, (src, _, tgt_y) in enumerate(training_data):\n","    #        prediction = run_encoder_decoder_inference(model=model, src=src, forecast_window=output_sequence_length,batch_size=src.shape[1])\n","    #        loss = criterion(tgt_y, prediction)"],"metadata":{"id":"ByryI2P9A1-E","executionInfo":{"status":"ok","timestamp":1670634452273,"user_tz":360,"elapsed":107220,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["i, batch = next(enumerate(training_data))\n","src, trg, trg_y = batch\n","model.eval()\n","with torch.no_grad():\n","  prediction = model(src=src,tgt=trg,src_mask=src_mask,tgt_mask=tgt_mask)"],"metadata":{"id":"Jz_D_yIGxNOB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(prediction[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"gLweHAMozHym","executionInfo":{"status":"ok","timestamp":1670638276722,"user_tz":360,"elapsed":446,"user":{"displayName":"Daniel Gómez Torres","userId":"12420692163461184890"}},"outputId":"978aef8f-b803-42e2-b5cb-2f4a0e43f4fb"},"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f18fd33eb80>]"]},"metadata":{},"execution_count":81},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}